<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jin, Lianwen | SCUT Visual Laboratory</title><link>https://SCUT-Xinlab.github.io/en/author/jin-lianwen/</link><atom:link href="https://SCUT-Xinlab.github.io/en/author/jin-lianwen/index.xml" rel="self" type="application/rss+xml"/><description>Jin, Lianwen</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sun, 01 Jan 2023 00:00:00 +0000</lastBuildDate><image><url>https://SCUT-Xinlab.github.io/media/icon_hu_7613a4a452ac7087.png</url><title>Jin, Lianwen</title><link>https://SCUT-Xinlab.github.io/en/author/jin-lianwen/</link></image><item><title>Skeleton-Based Gesture Recognition With Learnable Paths and Signature Features</title><link>https://SCUT-Xinlab.github.io/en/publication/journal-article/paper-cheng20233951/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://SCUT-Xinlab.github.io/en/publication/journal-article/paper-cheng20233951/</guid><description/></item><item><title>A Novel Unsupervised domain adaptation method for inertia-Trajectory translation of in-air handwriting</title><link>https://SCUT-Xinlab.github.io/en/publication/journal-article/paper-xu2021/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://SCUT-Xinlab.github.io/en/publication/journal-article/paper-xu2021/</guid><description/></item><item><title>Graph Convolutional Neural Network for Human Action Recognition: A Comprehensive Survey</title><link>https://SCUT-Xinlab.github.io/en/publication/journal-article/paper-ahmad2021128/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://SCUT-Xinlab.github.io/en/publication/journal-article/paper-ahmad2021128/</guid><description>&lt;p&gt;{% callout note %}
Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{% /callout %}&lt;/p&gt;
&lt;p&gt;Add the publication&amp;rsquo;s &lt;strong&gt;full text&lt;/strong&gt; or &lt;strong&gt;supplementary notes&lt;/strong&gt; here. You can use rich formatting such as including &lt;a href="https://docs.hugoblox.com/content/writing-markdown-latex/" target="_blank" rel="noopener"&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>Skeleton-based gesture recognition using several fully connected layers with path signature features and temporal transformer module</title><link>https://SCUT-Xinlab.github.io/en/publication/conference-paper/paper-li20198585/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>https://SCUT-Xinlab.github.io/en/publication/conference-paper/paper-li20198585/</guid><description/></item></channel></rss>